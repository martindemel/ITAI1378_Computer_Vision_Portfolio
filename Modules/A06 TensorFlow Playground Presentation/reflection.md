# A06 TensorFlow Playground Presentation

Our team dove into the world of neural networks using TensorFlow Playground. We focused on experimenting with key components and their effects on model performance:

**Key Concepts Explored:**

* **Activation Functions:** We tested and compared the performance of ReLU, Tanh, Sigmoid, and Linear activation functions on various datasets.
* **Hidden Layers:**  We investigated the impact of adding and removing hidden layers on model accuracy and complexity.
* **Learning Rates:** We adjusted learning rates to observe how they influence the speed and stability of model training.
* **Data Noise:** We introduced noise into datasets to see how well models generalize to real-world, imperfect data.
* **Dataset Exploration:** We worked with different datasets, including the challenging spiral dataset, to understand how data complexity affects model design.


**Key Takeaways:**

* TensorFlow Playground provided an intuitive and interactive way to visualize and understand the impact of different parameters on neural network training.
* We gained valuable insights into the trade-offs between model complexity, accuracy, and training time.
* The spiral dataset proved particularly challenging, highlighting the need for more complex architectures or feature engineering to achieve good performance.
